{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "model = ChatAnthropic(model='claude-3-7-sonnet-20250219', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"Write a poem about a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"# Whiskers in the Moonlight\\n\\nSilent paws upon the floor,\\nAmber eyes that watch and wait,\\nMidnight fur that's soft and sleek,\\nA purring soul, my feline mate.\\n\\nThrough windows gazing at the birds,\\nA hunter's heart beneath the calm,\\nStretching long in sunlight's beams,\\nYour presence is a soothing balm.\\n\\nMysterious in your quiet ways,\\nIndependent, proud, and free,\\nYet curled against me as I sleep,\\nA tender bond 'tween you and me.\\n\\nPlayful one moment, regal the next,\\nA contradiction wrapped in grace,\\nIn this home we share together,\\nYou've found your perfect resting place.\", additional_kwargs={}, response_metadata={'id': 'msg_014brD7kXomQitXDM7QPcZ3p', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 15, 'output_tokens': 167}}, id='run-097b49bb-7a19-43e9-b614-cc46aa70e6f4-0', usage_metadata={'input_tokens': 15, 'output_tokens': 167, 'total_tokens': 182, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Whiskers in the Moonlight\n",
       "\n",
       "Silent paws upon the floor,\n",
       "Amber eyes that watch and wait,\n",
       "Midnight fur that's soft and sleek,\n",
       "A purring soul, my feline mate.\n",
       "\n",
       "Through windows gazing at the birds,\n",
       "A hunter's heart beneath the calm,\n",
       "Stretching long in sunlight's beams,\n",
       "Your presence is a soothing balm.\n",
       "\n",
       "Mysterious in your quiet ways,\n",
       "Independent, proud, and free,\n",
       "Yet curled against me as I sleep,\n",
       "A tender bond 'tween you and me.\n",
       "\n",
       "Playful one moment, regal the next,\n",
       "A contradiction wrapped in grace,\n",
       "In this home we share together,\n",
       "You've found your perfect resting place."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "    Tell me a joke about {topic}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example prompt =  Write a detailed report on the {company_name} using the following information: {information}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='\\n    Tell me a joke about Tiger\\n')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"topic\": \"Tiger\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't tigers like fast food?\\n\\nBecause they can't catch it!\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_joke = model.invoke(prompt)\n",
    "\n",
    "response_joke.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content=' \\n    You are a helpful assiatnt that can translate a sentence from English to Spanish.\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='\\n    Translate the following sentence to Spanish: I love programming in Python\\n', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\" \n",
    "    You are a helpful assiatnt that can translate a sentence from English to {language}.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    Translate the following sentence to {language}: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", user_prompt)\n",
    "])\n",
    "\n",
    "prompt = prompt_template.invoke({\"sentence\": \"I love programming in Python\", \"language\": \"Spanish\"})\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=' \\n    You are a helpful assiatnt that can translate a sentence from English to Spanish.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='\\n    Translate the following sentence to Spanish: I love programming in Python\\n', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love programming in Python → Me encanta programar en Python'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "\n",
    "response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I love programming in Python → Me encanta programar en Python', additional_kwargs={}, response_metadata={'id': 'msg_01QR1ce753Spsxh5hppueoY7', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 40, 'output_tokens': 16}}, id='run-68b0dc9e-ec46-4e03-a689-ce45f20e4779-0', usage_metadata={'input_tokens': 40, 'output_tokens': 16, 'total_tokens': 56, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'ll translate that sentence to French for you:\\n\\n\"J\\'aime programmer en Python.\"'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "system_prompt = \"\"\" \n",
    "    You are a helpful assiatnt that can translate a sentence from English to {language}.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    Translate the following sentence to {language}: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "system_message = SystemMessage(content=system_prompt.format(language=\"French\"))\n",
    "user_message = HumanMessage(content=user_prompt.format(sentence=\"I love programming in Python\", language=\"French\"))\n",
    "\n",
    "\n",
    "messages = [system_message, user_message]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n",
    "response.content\n",
    "\n",
    "# Chaining\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape contents from a url and summarize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Introduction\\n- Anthropic announces Claude 3.7 Sonnet, their most intelligent model and first hybrid reasoning model\\n- Introduces Claude Code, a command line tool for agentic coding in limited research preview\\n\\n# Body\\n- Key features of Claude 3.7 Sonnet:\\n  - Available in standard and extended thinking modes\\n  - Shows significant improvements in coding and web development\\n  - Maintains same pricing as predecessors ($3/million input tokens, $15/million output tokens)\\n  - Available across all Claude plans and partner platforms\\n  - API users can control how long the model thinks before responding\\n  - Achieves state-of-the-art performance on SWE-bench Verified and TAU-bench\\n\\n- Claude Code capabilities:\\n  - Can search/read code, edit files, write/run tests, and use command line tools\\n  - Reduces development time for complex tasks\\n  - Currently in limited research preview\\n\\n# Key Takeaways\\n- Claude 3.7 Sonnet integrates quick responses and deep reasoning in a single model\\n- Significant improvements in real-world coding tasks confirmed by partners\\n- GitHub integration now available on all Claude plans\\n- Safety improvements include 45% reduction in unnecessary refusals\\n\\n# Conclusion\\n- These releases represent progress toward AI systems that can augment human capabilities\\n- Anthropic continues to focus on responsible development with detailed system card documentation'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "def scrape_text(url):\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    return article.text\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "    You are a helpful assistant that can summarize a text.\n",
    "\n",
    "    Guidelines:\n",
    "    - Summarize the text in a concise manner.\n",
    "    - Keep it short and to the point.\n",
    "\n",
    "    Output Format:\n",
    "     #Introduction\n",
    "     #Body\n",
    "      - Bullet points\n",
    "     #Key Takeaways\n",
    "     #Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    Summarize the following text: {text}\n",
    "\"\"\"\n",
    "\n",
    "system_message = SystemMessage(content=system_prompt)\n",
    "\n",
    "url = \"https://www.anthropic.com/news/claude-3-7-sonnet\"\n",
    "\n",
    "user_message = HumanMessage(content=user_prompt.format(text=scrape_text(url)))\n",
    "\n",
    "messages = [system_message, user_message]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Introduction\n",
       "- Anthropic announces Claude 3.7 Sonnet, their most intelligent model and first hybrid reasoning model\n",
       "- Introduces Claude Code, a command line tool for agentic coding in limited research preview\n",
       "\n",
       "# Body\n",
       "- Key features of Claude 3.7 Sonnet:\n",
       "  - Available in standard and extended thinking modes\n",
       "  - Shows significant improvements in coding and web development\n",
       "  - Maintains same pricing as predecessors ($3/million input tokens, $15/million output tokens)\n",
       "  - Available across all Claude plans and partner platforms\n",
       "  - API users can control how long the model thinks before responding\n",
       "  - Achieves state-of-the-art performance on SWE-bench Verified and TAU-bench\n",
       "\n",
       "- Claude Code capabilities:\n",
       "  - Can search/read code, edit files, write/run tests, and use command line tools\n",
       "  - Reduces development time for complex tasks\n",
       "  - Currently in limited research preview\n",
       "\n",
       "# Key Takeaways\n",
       "- Claude 3.7 Sonnet integrates quick responses and deep reasoning in a single model\n",
       "- Significant improvements in real-world coding tasks confirmed by partners\n",
       "- GitHub integration now available on all Claude plans\n",
       "- Safety improvements include 45% reduction in unnecessary refusals\n",
       "\n",
       "# Conclusion\n",
       "- These releases represent progress toward AI systems that can augment human capabilities\n",
       "- Anthropic continues to focus on responsible development with detailed system card documentation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
