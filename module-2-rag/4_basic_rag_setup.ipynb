{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RAG Architecture](./images/rag_screehnshot.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pine cone setup \n",
    "pip install pinecone\n",
    "\n",
    "Add API KEY in .env\n",
    "\n",
    "\n",
    "Langchain doc- https://python.langchain.com/docs/integrations/vectorstores/pinecone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hrithikkoduri/Desktop/Course/venv/lib/python3.13/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Vector DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"langchain-test-index\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap =10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"./data/appendix-keywords.txt\", encoding=\"utf-8\") as f:\n",
    "   file = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Semantic Search\\n\\nDefinition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.\\nRelated keywords: embedding, database, vectorization, vectorization\\n\\nEmbedding\\n\\nDefinition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to understand and process the text.\\nExample: Represent the word “apple” as a vector such as [0.65, -0.23, 0.17].\\nRelated keywords: natural language processing, vectorization, deep learning\\n\\nToken\\n\\nDefinition: A token is a breakup of text into smaller units. These can typically be words, sentences, or phrases.\\nExample: Split the sentence “I am going to school” into “I am”, “to school”, and “going”.\\nAssociated keywords: tokenization, natural language processing, parsing\\n\\nTokenizer\\n\\nDefinition: A tokenizer is a tool that splits text data into tokens. It is used to preprocess data in natural language processing.\\nExample: Split the sentence “I love programming.” into [“I”, “love”, “programming”, “.”].\\nAssociated keywords: tokenization, natural language processing, parsing\\n\\nVectorStore\\n\\nDefinition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.\\nRelated keywords: embedding, database, vectorization, vectorization\\n\\nSQL\\n\\nDefinition: SQL(Structured Query Language) is a programming language for managing data in a database. You can query, modify, insert, delete, and more data.\\nExample: SELECT * FROM users WHERE age > 18; looks up information about users who are 18 years old or older.\\nAssociated keywords: database, query, data management, data management\\n\\nCSV\\n\\nDefinition: CSV(Comma-Separated Values) is a file format for storing data, where each data value is separated by a comma. It is used for simple storage and exchange of tabular data.\\nExample: A CSV file with the headers Name, Age, and Occupation might contain data such as Hong Gil-dong, 30, Developer.\\nRelated keywords: data format, file processing, data exchange\\n\\nJSON\\n\\nDefinition: JSON(JavaScript Object Notation) is a lightweight data interchange format that represents data objects using text that is readable to both humans and machines.\\nExample: {“Name”: “HongGilDong”, ‘Age’: 30, “Occupation”: “Developer\"} is data in JSON format.\\nRelated keywords: data exchange, web development, APIs\\n\\nTransformer\\n\\nDefinition: Transformers are a type of deep learning model used in natural language processing, mainly for translation, summarization, text generation, etc. It is based on the Attention mechanism.\\nExample: Google Translator uses transformer models to perform translations between different languages.\\nRelated keywords: Deep learning, Natural language processing, Attention\\n\\nHuggingFace\\n\\nDefinition: HuggingFace is a library that provides a variety of pre-trained models and tools for natural language processing. It helps researchers and developers to easily perform NLP tasks.\\nExample: You can use HuggingFace\\'s Transformers library to perform tasks such as sentiment analysis, text generation, and more.\\nRelated keywords: natural language processing, deep learning, libraries\\n\\nDigital Transformation\\n\\nDefinition: Digital transformation is the process of leveraging technology to transform a company\\'s services, culture, and operations. It focuses on improving business models and increasing competitiveness through digital technologies.\\nExample: When a company adopts cloud computing to revolutionize data storage and processing, it\\'s an example of digital transformation.\\nRelated keywords: transformation, technology, business model\\n\\nCrawling\\n\\nDefinition: Crawling is the process of visiting web pages in an automated way to collect data. It is often used for search engine optimization or data analysis.\\nExample: When the Google search engine visits websites on the internet to collect and index content, it is crawling.\\nRelated keywords: data collection, web scraping, search engine\\n\\nWord2Vec\\n\\nDefinition: Word2Vec is a natural language processing technique that maps words to a vector space to represent semantic relationships between words. It generates vectors based on the contextual similarity of words.\\nExample: In a Word2Vec model, “king” and “queen” are represented as vectors in close proximity to each other.\\nRelated keywords: natural language processing, embeddings, semantic similarity\\n\\nLLM (Large Language Model)\\n\\nDefinition: LLM refers to large-scale language models trained on large amounts of textual data. These models are used for a variety of natural language understanding and generation tasks.\\nExample: OpenAI\\'s GPT series is a typical large-scale language model.\\nRelated keywords: natural language processing, deep learning, text generation\\n\\nFAISS (Facebook AI Similarity Search)\\n\\nDefinition: FAISS is a fast similarity search library developed by Facebook, specifically designed to efficiently search for similar vectors in large vector sets.\\nExample: FAISS can be used to quickly find similar images among millions of image vectors.\\nRelated keywords: vector search, machine learning, database optimization\\n\\nOpen Source\\n\\nDefinition: Open source refers to software whose source code is publicly available and can be freely used, modified, and distributed by anyone. This plays an important role in fostering collaboration and innovation.\\nExample: The Linux operating system is a prominent open source project.\\nRelated keywords: software development, community, technical collaboration\\n\\nStructured Data\\n\\nDefinition: Structured data is data that is organized according to a set format or schema. It can be easily searched and analyzed in databases, spreadsheets, etc.\\nExample: A table of customer information stored in a relational database is an example of structured data.\\nRelated keywords: database, data analysis, data modeling, data modeling\\n\\nParser\\n\\nDefinition: A parser is a tool that analyzes given data (strings, files, etc.) and converts it into a structured form. It is used for parsing programming languages or processing file data.\\nExample: Parsing an HTML document to generate the DOM structure of a web page is an example of parsing.\\nAssociated keywords: parsing, compiler, data processing\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)\\n\\nDefinition: TF-IDF is a statistical measure used to evaluate the importance of a word within a document. It takes into account the frequency of the word within the document and the sparsity of the word in the entire document set.\\nExample: A word that occurs infrequently in many documents has a high TF-IDF value.\\nRelated keywords: natural language processing, information retrieval, data mining\\n\\nDeep Learning\\n\\nDefinition: Deep learning is a branch of machine learning that uses artificial neural networks to solve complex problems. It focuses on learning high-level representations from data.\\nExamples: Deep learning models are used in image recognition, speech recognition, natural language processing, and more.\\nRelated keywords: Artificial neural networks, machine learning, data analytics\\n\\nSchema\\n\\nDefinition: A schema defines the structure of a database or file, providing a blueprint for how data is stored and organized.\\nExample: The table schema of a relational database defines column names, data types, key constraints, and more.\\nRelated keywords: database, data modeling, data management, data management\\n\\nDataFrame\\n\\nDefinition: A DataFrame is a table-like data structure with rows and columns, primarily used for data analysis and processing.\\nExample: In the Pandas library, a DataFrame can have columns of different data types and facilitates data manipulation and analysis.\\nRelated keywords: data analytics, Pandas, data processing\\n\\nAttention mechanisms\\n\\nDefinition: Attention mechanisms are techniques that allow deep learning to pay more “attention” to important information. They are often used with sequential data (e.g., text, time series data).\\nExample: In a translation model, the Attention mechanism focuses more on the important parts of the input sentence to produce an accurate translation.\\nAssociated keywords: deep learning, natural language processing, sequence modeling\\n\\nPandas\\n\\nDefinition: Pandas is a library that provides data analysis and manipulation tools for the Python programming language. It enables you to perform data analysis tasks efficiently.\\nExample: You can use Pandas to read CSV files, cleanse data, and perform various analyses.\\nRelated keywords: Data analysis, Python, Data processing\\n\\nGPT (Generative Pretrained Transformer)\\n\\nDefinition: GPTs are generative language models pre-trained on large datasets and utilized for a variety of text-based tasks. It can generate natural language based on input text.\\nExample: A chatbot that generates detailed answers to user-supplied questions can use a GPT model.\\nRelated keywords: natural language processing, text generation, deep learning\\n\\nInstructGPT\\n\\nDefinition: InstructGPT is a GPT model optimized to perform specific tasks based on user instructions. The model is designed to produce more accurate and relevant results.\\nExample: If a user provides a specific instruction, such as “draft an email,” InstructGPT will create an email based on relevant content.\\nRelated keywords: artificial intelligence, natural language understanding, command-based processing\\n\\nKeyword Search\\n\\nDefinition: Keyword search is the process of finding information based on keywords entered by a user. It is the primary search method used by most search engines and database systems.\\nExample: If a user searches for “coffee shops Seoul”, a list of relevant coffee shops is returned.\\nRelated keywords: search engine, data search, information search\\n\\nPage Rank\\n\\nDefinition: PageRank is an algorithm that evaluates the importance of a web page and is primarily used to determine its ranking in search engine results. It is evaluated by analyzing the link structure between web pages.\\nExample: The Google search engine uses the PageRank algorithm to rank search results.\\nRelated keywords: search engine optimization, web analytics, link analysis\\n\\nData Mining\\n\\nDefinition: Data mining is the process of uncovering useful information from large amounts of data. It leverages techniques such as statistics, machine learning, and pattern recognition.\\nExample: When a retailer analyzes customer purchase data to create a sales strategy, it\\'s an example of data mining.\\nRelated keywords: big data, pattern recognition, predictive analytics\\n\\nMultimodal (Multimodal)\\n\\nDefinition: Multimodal is a technique that combines and processes multiple modes of data (e.g., text, images, sound, etc.). It is used to extract or predict richer and more accurate information through the interaction between different forms of data.\\nExample: A system that analyzes images and descriptive text together to perform more accurate image classification is an example of multimodal technology.\\nRelated keywords: data fusion, artificial intelligence, deep learning'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Semantic Search\\n\\nDefinition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.\\nRelated keywords: embedding, database, vectorization, vectorization\\n\\nEmbedding\\n\\nDefinition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to understand and process the text.\\nExample: Represent the word “apple” as a vector such as [0.65, -0.23, 0.17].\\nRelated keywords: natural language processing, vectorization, deep learning\\n\\nToken\\n\\nDefinition: A token is a breakup of text into smaller units. These can typically be words, sentences, or phrases.\\nExample: Split the sentence “I am going to school” into “I am”, “to school”, and “going”.\\nAssociated keywords: tokenization, natural language processing, parsing\\n\\nTokenizer'),\n",
       " Document(metadata={}, page_content='Tokenizer\\n\\nDefinition: A tokenizer is a tool that splits text data into tokens. It is used to preprocess data in natural language processing.\\nExample: Split the sentence “I love programming.” into [“I”, “love”, “programming”, “.”].\\nAssociated keywords: tokenization, natural language processing, parsing\\n\\nVectorStore\\n\\nDefinition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.\\nRelated keywords: embedding, database, vectorization, vectorization\\n\\nSQL\\n\\nDefinition: SQL(Structured Query Language) is a programming language for managing data in a database. You can query, modify, insert, delete, and more data.\\nExample: SELECT * FROM users WHERE age > 18; looks up information about users who are 18 years old or older.\\nAssociated keywords: database, query, data management, data management\\n\\nCSV'),\n",
       " Document(metadata={}, page_content='CSV\\n\\nDefinition: CSV(Comma-Separated Values) is a file format for storing data, where each data value is separated by a comma. It is used for simple storage and exchange of tabular data.\\nExample: A CSV file with the headers Name, Age, and Occupation might contain data such as Hong Gil-dong, 30, Developer.\\nRelated keywords: data format, file processing, data exchange\\n\\nJSON\\n\\nDefinition: JSON(JavaScript Object Notation) is a lightweight data interchange format that represents data objects using text that is readable to both humans and machines.\\nExample: {“Name”: “HongGilDong”, ‘Age’: 30, “Occupation”: “Developer\"} is data in JSON format.\\nRelated keywords: data exchange, web development, APIs\\n\\nTransformer'),\n",
       " Document(metadata={}, page_content=\"Definition: Transformers are a type of deep learning model used in natural language processing, mainly for translation, summarization, text generation, etc. It is based on the Attention mechanism.\\nExample: Google Translator uses transformer models to perform translations between different languages.\\nRelated keywords: Deep learning, Natural language processing, Attention\\n\\nHuggingFace\\n\\nDefinition: HuggingFace is a library that provides a variety of pre-trained models and tools for natural language processing. It helps researchers and developers to easily perform NLP tasks.\\nExample: You can use HuggingFace's Transformers library to perform tasks such as sentiment analysis, text generation, and more.\\nRelated keywords: natural language processing, deep learning, libraries\\n\\nDigital Transformation\"),\n",
       " Document(metadata={}, page_content=\"Definition: Digital transformation is the process of leveraging technology to transform a company's services, culture, and operations. It focuses on improving business models and increasing competitiveness through digital technologies.\\nExample: When a company adopts cloud computing to revolutionize data storage and processing, it's an example of digital transformation.\\nRelated keywords: transformation, technology, business model\\n\\nCrawling\\n\\nDefinition: Crawling is the process of visiting web pages in an automated way to collect data. It is often used for search engine optimization or data analysis.\\nExample: When the Google search engine visits websites on the internet to collect and index content, it is crawling.\\nRelated keywords: data collection, web scraping, search engine\\n\\nWord2Vec\"),\n",
       " Document(metadata={}, page_content=\"Word2Vec\\n\\nDefinition: Word2Vec is a natural language processing technique that maps words to a vector space to represent semantic relationships between words. It generates vectors based on the contextual similarity of words.\\nExample: In a Word2Vec model, “king” and “queen” are represented as vectors in close proximity to each other.\\nRelated keywords: natural language processing, embeddings, semantic similarity\\n\\nLLM (Large Language Model)\\n\\nDefinition: LLM refers to large-scale language models trained on large amounts of textual data. These models are used for a variety of natural language understanding and generation tasks.\\nExample: OpenAI's GPT series is a typical large-scale language model.\\nRelated keywords: natural language processing, deep learning, text generation\\n\\nFAISS (Facebook AI Similarity Search)\"),\n",
       " Document(metadata={}, page_content='Definition: FAISS is a fast similarity search library developed by Facebook, specifically designed to efficiently search for similar vectors in large vector sets.\\nExample: FAISS can be used to quickly find similar images among millions of image vectors.\\nRelated keywords: vector search, machine learning, database optimization\\n\\nOpen Source\\n\\nDefinition: Open source refers to software whose source code is publicly available and can be freely used, modified, and distributed by anyone. This plays an important role in fostering collaboration and innovation.\\nExample: The Linux operating system is a prominent open source project.\\nRelated keywords: software development, community, technical collaboration\\n\\nStructured Data'),\n",
       " Document(metadata={}, page_content='Definition: Structured data is data that is organized according to a set format or schema. It can be easily searched and analyzed in databases, spreadsheets, etc.\\nExample: A table of customer information stored in a relational database is an example of structured data.\\nRelated keywords: database, data analysis, data modeling, data modeling\\n\\nParser\\n\\nDefinition: A parser is a tool that analyzes given data (strings, files, etc.) and converts it into a structured form. It is used for parsing programming languages or processing file data.\\nExample: Parsing an HTML document to generate the DOM structure of a web page is an example of parsing.\\nAssociated keywords: parsing, compiler, data processing\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
       " Document(metadata={}, page_content='Definition: TF-IDF is a statistical measure used to evaluate the importance of a word within a document. It takes into account the frequency of the word within the document and the sparsity of the word in the entire document set.\\nExample: A word that occurs infrequently in many documents has a high TF-IDF value.\\nRelated keywords: natural language processing, information retrieval, data mining\\n\\nDeep Learning\\n\\nDefinition: Deep learning is a branch of machine learning that uses artificial neural networks to solve complex problems. It focuses on learning high-level representations from data.\\nExamples: Deep learning models are used in image recognition, speech recognition, natural language processing, and more.\\nRelated keywords: Artificial neural networks, machine learning, data analytics\\n\\nSchema'),\n",
       " Document(metadata={}, page_content='Schema\\n\\nDefinition: A schema defines the structure of a database or file, providing a blueprint for how data is stored and organized.\\nExample: The table schema of a relational database defines column names, data types, key constraints, and more.\\nRelated keywords: database, data modeling, data management, data management\\n\\nDataFrame\\n\\nDefinition: A DataFrame is a table-like data structure with rows and columns, primarily used for data analysis and processing.\\nExample: In the Pandas library, a DataFrame can have columns of different data types and facilitates data manipulation and analysis.\\nRelated keywords: data analytics, Pandas, data processing\\n\\nAttention mechanisms'),\n",
       " Document(metadata={}, page_content='Definition: Attention mechanisms are techniques that allow deep learning to pay more “attention” to important information. They are often used with sequential data (e.g., text, time series data).\\nExample: In a translation model, the Attention mechanism focuses more on the important parts of the input sentence to produce an accurate translation.\\nAssociated keywords: deep learning, natural language processing, sequence modeling\\n\\nPandas\\n\\nDefinition: Pandas is a library that provides data analysis and manipulation tools for the Python programming language. It enables you to perform data analysis tasks efficiently.\\nExample: You can use Pandas to read CSV files, cleanse data, and perform various analyses.\\nRelated keywords: Data analysis, Python, Data processing\\n\\nGPT (Generative Pretrained Transformer)'),\n",
       " Document(metadata={}, page_content='Definition: GPTs are generative language models pre-trained on large datasets and utilized for a variety of text-based tasks. It can generate natural language based on input text.\\nExample: A chatbot that generates detailed answers to user-supplied questions can use a GPT model.\\nRelated keywords: natural language processing, text generation, deep learning\\n\\nInstructGPT\\n\\nDefinition: InstructGPT is a GPT model optimized to perform specific tasks based on user instructions. The model is designed to produce more accurate and relevant results.\\nExample: If a user provides a specific instruction, such as “draft an email,” InstructGPT will create an email based on relevant content.\\nRelated keywords: artificial intelligence, natural language understanding, command-based processing\\n\\nKeyword Search'),\n",
       " Document(metadata={}, page_content='Definition: Keyword search is the process of finding information based on keywords entered by a user. It is the primary search method used by most search engines and database systems.\\nExample: If a user searches for “coffee shops Seoul”, a list of relevant coffee shops is returned.\\nRelated keywords: search engine, data search, information search\\n\\nPage Rank\\n\\nDefinition: PageRank is an algorithm that evaluates the importance of a web page and is primarily used to determine its ranking in search engine results. It is evaluated by analyzing the link structure between web pages.\\nExample: The Google search engine uses the PageRank algorithm to rank search results.\\nRelated keywords: search engine optimization, web analytics, link analysis\\n\\nData Mining'),\n",
       " Document(metadata={}, page_content=\"Definition: Data mining is the process of uncovering useful information from large amounts of data. It leverages techniques such as statistics, machine learning, and pattern recognition.\\nExample: When a retailer analyzes customer purchase data to create a sales strategy, it's an example of data mining.\\nRelated keywords: big data, pattern recognition, predictive analytics\\n\\nMultimodal (Multimodal)\\n\\nDefinition: Multimodal is a technique that combines and processes multiple modes of data (e.g., text, images, sound, etc.). It is used to extract or predict richer and more accurate information through the interaction between different forms of data.\\nExample: A system that analyzes images and descriptive text together to perform more accurate image classification is an example of multimodal technology.\\nRelated keywords: data fusion, artificial intelligence, deep learning\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks =  text_splitter.create_documents([file])\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'appendix-keywords.txt'}, page_content='Semantic Search\\n\\nDefinition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.\\nRelated keywords: embedding, database, vectorization, vectorization\\n\\nEmbedding\\n\\nDefinition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to understand and process the text.\\nExample: Represent the word “apple” as a vector such as [0.65, -0.23, 0.17].\\nRelated keywords: natural language processing, vectorization, deep learning\\n\\nToken\\n\\nDefinition: A token is a breakup of text into smaller units. These can typically be words, sentences, or phrases.\\nExample: Split the sentence “I am going to school” into “I am”, “to school”, and “going”.\\nAssociated keywords: tokenization, natural language processing, parsing\\n\\nTokenizer'),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content='Tokenizer\\n\\nDefinition: A tokenizer is a tool that splits text data into tokens. It is used to preprocess data in natural language processing.\\nExample: Split the sentence “I love programming.” into [“I”, “love”, “programming”, “.”].\\nAssociated keywords: tokenization, natural language processing, parsing\\n\\nVectorStore\\n\\nDefinition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.\\nRelated keywords: embedding, database, vectorization, vectorization\\n\\nSQL\\n\\nDefinition: SQL(Structured Query Language) is a programming language for managing data in a database. You can query, modify, insert, delete, and more data.\\nExample: SELECT * FROM users WHERE age > 18; looks up information about users who are 18 years old or older.\\nAssociated keywords: database, query, data management, data management\\n\\nCSV'),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content='CSV\\n\\nDefinition: CSV(Comma-Separated Values) is a file format for storing data, where each data value is separated by a comma. It is used for simple storage and exchange of tabular data.\\nExample: A CSV file with the headers Name, Age, and Occupation might contain data such as Hong Gil-dong, 30, Developer.\\nRelated keywords: data format, file processing, data exchange\\n\\nJSON\\n\\nDefinition: JSON(JavaScript Object Notation) is a lightweight data interchange format that represents data objects using text that is readable to both humans and machines.\\nExample: {“Name”: “HongGilDong”, ‘Age’: 30, “Occupation”: “Developer\"} is data in JSON format.\\nRelated keywords: data exchange, web development, APIs\\n\\nTransformer'),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content=\"Definition: Transformers are a type of deep learning model used in natural language processing, mainly for translation, summarization, text generation, etc. It is based on the Attention mechanism.\\nExample: Google Translator uses transformer models to perform translations between different languages.\\nRelated keywords: Deep learning, Natural language processing, Attention\\n\\nHuggingFace\\n\\nDefinition: HuggingFace is a library that provides a variety of pre-trained models and tools for natural language processing. It helps researchers and developers to easily perform NLP tasks.\\nExample: You can use HuggingFace's Transformers library to perform tasks such as sentiment analysis, text generation, and more.\\nRelated keywords: natural language processing, deep learning, libraries\\n\\nDigital Transformation\"),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content=\"Definition: Digital transformation is the process of leveraging technology to transform a company's services, culture, and operations. It focuses on improving business models and increasing competitiveness through digital technologies.\\nExample: When a company adopts cloud computing to revolutionize data storage and processing, it's an example of digital transformation.\\nRelated keywords: transformation, technology, business model\\n\\nCrawling\\n\\nDefinition: Crawling is the process of visiting web pages in an automated way to collect data. It is often used for search engine optimization or data analysis.\\nExample: When the Google search engine visits websites on the internet to collect and index content, it is crawling.\\nRelated keywords: data collection, web scraping, search engine\\n\\nWord2Vec\"),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content=\"Word2Vec\\n\\nDefinition: Word2Vec is a natural language processing technique that maps words to a vector space to represent semantic relationships between words. It generates vectors based on the contextual similarity of words.\\nExample: In a Word2Vec model, “king” and “queen” are represented as vectors in close proximity to each other.\\nRelated keywords: natural language processing, embeddings, semantic similarity\\n\\nLLM (Large Language Model)\\n\\nDefinition: LLM refers to large-scale language models trained on large amounts of textual data. These models are used for a variety of natural language understanding and generation tasks.\\nExample: OpenAI's GPT series is a typical large-scale language model.\\nRelated keywords: natural language processing, deep learning, text generation\\n\\nFAISS (Facebook AI Similarity Search)\"),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content='Definition: FAISS is a fast similarity search library developed by Facebook, specifically designed to efficiently search for similar vectors in large vector sets.\\nExample: FAISS can be used to quickly find similar images among millions of image vectors.\\nRelated keywords: vector search, machine learning, database optimization\\n\\nOpen Source\\n\\nDefinition: Open source refers to software whose source code is publicly available and can be freely used, modified, and distributed by anyone. This plays an important role in fostering collaboration and innovation.\\nExample: The Linux operating system is a prominent open source project.\\nRelated keywords: software development, community, technical collaboration\\n\\nStructured Data'),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content='Definition: Structured data is data that is organized according to a set format or schema. It can be easily searched and analyzed in databases, spreadsheets, etc.\\nExample: A table of customer information stored in a relational database is an example of structured data.\\nRelated keywords: database, data analysis, data modeling, data modeling\\n\\nParser\\n\\nDefinition: A parser is a tool that analyzes given data (strings, files, etc.) and converts it into a structured form. It is used for parsing programming languages or processing file data.\\nExample: Parsing an HTML document to generate the DOM structure of a web page is an example of parsing.\\nAssociated keywords: parsing, compiler, data processing\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content='Definition: TF-IDF is a statistical measure used to evaluate the importance of a word within a document. It takes into account the frequency of the word within the document and the sparsity of the word in the entire document set.\\nExample: A word that occurs infrequently in many documents has a high TF-IDF value.\\nRelated keywords: natural language processing, information retrieval, data mining\\n\\nDeep Learning\\n\\nDefinition: Deep learning is a branch of machine learning that uses artificial neural networks to solve complex problems. It focuses on learning high-level representations from data.\\nExamples: Deep learning models are used in image recognition, speech recognition, natural language processing, and more.\\nRelated keywords: Artificial neural networks, machine learning, data analytics\\n\\nSchema'),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content='Schema\\n\\nDefinition: A schema defines the structure of a database or file, providing a blueprint for how data is stored and organized.\\nExample: The table schema of a relational database defines column names, data types, key constraints, and more.\\nRelated keywords: database, data modeling, data management, data management\\n\\nDataFrame\\n\\nDefinition: A DataFrame is a table-like data structure with rows and columns, primarily used for data analysis and processing.\\nExample: In the Pandas library, a DataFrame can have columns of different data types and facilitates data manipulation and analysis.\\nRelated keywords: data analytics, Pandas, data processing\\n\\nAttention mechanisms'),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content='Definition: Attention mechanisms are techniques that allow deep learning to pay more “attention” to important information. They are often used with sequential data (e.g., text, time series data).\\nExample: In a translation model, the Attention mechanism focuses more on the important parts of the input sentence to produce an accurate translation.\\nAssociated keywords: deep learning, natural language processing, sequence modeling\\n\\nPandas\\n\\nDefinition: Pandas is a library that provides data analysis and manipulation tools for the Python programming language. It enables you to perform data analysis tasks efficiently.\\nExample: You can use Pandas to read CSV files, cleanse data, and perform various analyses.\\nRelated keywords: Data analysis, Python, Data processing\\n\\nGPT (Generative Pretrained Transformer)'),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content='Definition: GPTs are generative language models pre-trained on large datasets and utilized for a variety of text-based tasks. It can generate natural language based on input text.\\nExample: A chatbot that generates detailed answers to user-supplied questions can use a GPT model.\\nRelated keywords: natural language processing, text generation, deep learning\\n\\nInstructGPT\\n\\nDefinition: InstructGPT is a GPT model optimized to perform specific tasks based on user instructions. The model is designed to produce more accurate and relevant results.\\nExample: If a user provides a specific instruction, such as “draft an email,” InstructGPT will create an email based on relevant content.\\nRelated keywords: artificial intelligence, natural language understanding, command-based processing\\n\\nKeyword Search'),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content='Definition: Keyword search is the process of finding information based on keywords entered by a user. It is the primary search method used by most search engines and database systems.\\nExample: If a user searches for “coffee shops Seoul”, a list of relevant coffee shops is returned.\\nRelated keywords: search engine, data search, information search\\n\\nPage Rank\\n\\nDefinition: PageRank is an algorithm that evaluates the importance of a web page and is primarily used to determine its ranking in search engine results. It is evaluated by analyzing the link structure between web pages.\\nExample: The Google search engine uses the PageRank algorithm to rank search results.\\nRelated keywords: search engine optimization, web analytics, link analysis\\n\\nData Mining'),\n",
       " Document(metadata={'source': 'appendix-keywords.txt'}, page_content=\"Definition: Data mining is the process of uncovering useful information from large amounts of data. It leverages techniques such as statistics, machine learning, and pattern recognition.\\nExample: When a retailer analyzes customer purchase data to create a sales strategy, it's an example of data mining.\\nRelated keywords: big data, pattern recognition, predictive analytics\\n\\nMultimodal (Multimodal)\\n\\nDefinition: Multimodal is a technique that combines and processes multiple modes of data (e.g., text, images, sound, etc.). It is used to extract or predict richer and more accurate information through the interaction between different forms of data.\\nExample: A system that analyzes images and descriptive text together to perform more accurate image classification is an example of multimodal technology.\\nRelated keywords: data fusion, artificial intelligence, deep learning\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.metadata = {\"source\": \"appendix-keywords.txt\"}\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associate ids with each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(chunks))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ffb63d4c-05aa-4b17-be28-d65a031ed75a',\n",
       " '70bd099d-d1db-488b-bd0b-2d7247b3d865',\n",
       " 'a701e729-d87f-4714-810e-f640351bd498',\n",
       " 'a23454ac-5b34-46f2-897d-cadb25b2948a',\n",
       " '6a2b3010-5a0a-4a71-bb73-44effc39c8cd',\n",
       " 'd27bf8f4-883f-4694-8812-cf1dcf3d8e30',\n",
       " '4223cae7-00fc-44d1-a133-b2cdb5b42757',\n",
       " 'b4b1da28-fcf0-4482-9187-8910b5788be7',\n",
       " '631fffc1-c90b-42f6-a8a3-979f8865c256',\n",
       " '43946758-a20a-4ffc-82af-164f2b970fcb',\n",
       " '8bab8a2f-903e-4e0a-876d-0baece5c73b3',\n",
       " '21d123bf-be1f-47f9-b176-0b2dcf7fa53c',\n",
       " 'e2a1216f-fe23-464f-b92f-3a6c376ec3f9',\n",
       " 'e982248e-08cf-4cf4-992e-80517b57181b']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store embeddings in vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ffb63d4c-05aa-4b17-be28-d65a031ed75a',\n",
       " '70bd099d-d1db-488b-bd0b-2d7247b3d865',\n",
       " 'a701e729-d87f-4714-810e-f640351bd498',\n",
       " 'a23454ac-5b34-46f2-897d-cadb25b2948a',\n",
       " '6a2b3010-5a0a-4a71-bb73-44effc39c8cd',\n",
       " 'd27bf8f4-883f-4694-8812-cf1dcf3d8e30',\n",
       " '4223cae7-00fc-44d1-a133-b2cdb5b42757',\n",
       " 'b4b1da28-fcf0-4482-9187-8910b5788be7',\n",
       " '631fffc1-c90b-42f6-a8a3-979f8865c256',\n",
       " '43946758-a20a-4ffc-82af-164f2b970fcb',\n",
       " '8bab8a2f-903e-4e0a-876d-0baece5c73b3',\n",
       " '21d123bf-be1f-47f9-b176-0b2dcf7fa53c',\n",
       " 'e2a1216f-fe23-464f-b92f-3a6c376ec3f9',\n",
       " 'e982248e-08cf-4cf4-992e-80517b57181b']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=chunks, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve using Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Tokenizer\n",
      "\n",
      "Definition: A tokenizer is a tool that splits text data into tokens. It is used to preprocess data in natural language processing.\n",
      "Example: Split the sentence “I love programming.” into [“I”, “love”, “programming”, “.”].\n",
      "Associated keywords: tokenization, natural language processing, parsing\n",
      "\n",
      "VectorStore\n",
      "\n",
      "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
      "Example: Vectors of word embeddings can be stored in a database for quick access.\n",
      "Related keywords: embedding, database, vectorization, vectorization\n",
      "\n",
      "SQL\n",
      "\n",
      "Definition: SQL(Structured Query Language) is a programming language for managing data in a database. You can query, modify, insert, delete, and more data.\n",
      "Example: SELECT * FROM users WHERE age > 18; looks up information about users who are 18 years old or older.\n",
      "Associated keywords: database, query, data management, data management\n",
      "\n",
      "CSV [{'source': 'appendix-keywords.txt'}]\n",
      "* Semantic Search\n",
      "\n",
      "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
      "Example: Vectors of word embeddings can be stored in a database for quick access.\n",
      "Related keywords: embedding, database, vectorization, vectorization\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to understand and process the text.\n",
      "Example: Represent the word “apple” as a vector such as [0.65, -0.23, 0.17].\n",
      "Related keywords: natural language processing, vectorization, deep learning\n",
      "\n",
      "Token\n",
      "\n",
      "Definition: A token is a breakup of text into smaller units. These can typically be words, sentences, or phrases.\n",
      "Example: Split the sentence “I am going to school” into “I am”, “to school”, and “going”.\n",
      "Associated keywords: tokenization, natural language processing, parsing\n",
      "\n",
      "Tokenizer [{'source': 'appendix-keywords.txt'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"What is a vector store?\",\n",
    "    k=2,\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve using similarity search and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.087242] Definition: Transformers are a type of deep learning model used in natural language processing, mainly for translation, summarization, text generation, etc. It is based on the Attention mechanism.\n",
      "Example: Google Translator uses transformer models to perform translations between different languages.\n",
      "Related keywords: Deep learning, Natural language processing, Attention\n",
      "\n",
      "HuggingFace\n",
      "\n",
      "Definition: HuggingFace is a library that provides a variety of pre-trained models and tools for natural language processing. It helps researchers and developers to easily perform NLP tasks.\n",
      "Example: You can use HuggingFace's Transformers library to perform tasks such as sentiment analysis, text generation, and more.\n",
      "Related keywords: natural language processing, deep learning, libraries\n",
      "\n",
      "Digital Transformation [{'source': 'appendix-keywords.txt'}]\n",
      "* [SIM=0.072915] Definition: Structured data is data that is organized according to a set format or schema. It can be easily searched and analyzed in databases, spreadsheets, etc.\n",
      "Example: A table of customer information stored in a relational database is an example of structured data.\n",
      "Related keywords: database, data analysis, data modeling, data modeling\n",
      "\n",
      "Parser\n",
      "\n",
      "Definition: A parser is a tool that analyzes given data (strings, files, etc.) and converts it into a structured form. It is used for parsing programming languages or processing file data.\n",
      "Example: Parsing an HTML document to generate the DOM structure of a web page is an example of parsing.\n",
      "Associated keywords: parsing, compiler, data processing\n",
      "\n",
      "TF-IDF (Term Frequency-Inverse Document Frequency) [{'source': 'appendix-keywords.txt'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Will it be hot tomorrow?\", k=2\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using custom retriever\n",
    "- similairty score\n",
    "- threshold for similarity score\n",
    "- number of documets to retrieve (k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='70bd099d-d1db-488b-bd0b-2d7247b3d865', metadata={'source': 'appendix-keywords.txt'}, page_content='Tokenizer\\n\\nDefinition: A tokenizer is a tool that splits text data into tokens. It is used to preprocess data in natural language processing.\\nExample: Split the sentence “I love programming.” into [“I”, “love”, “programming”, “.”].\\nAssociated keywords: tokenization, natural language processing, parsing\\n\\nVectorStore\\n\\nDefinition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.\\nRelated keywords: embedding, database, vectorization, vectorization\\n\\nSQL\\n\\nDefinition: SQL(Structured Query Language) is a programming language for managing data in a database. You can query, modify, insert, delete, and more data.\\nExample: SELECT * FROM users WHERE age > 18; looks up information about users who are 18 years old or older.\\nAssociated keywords: database, query, data management, data management\\n\\nCSV'),\n",
       " Document(id='ffb63d4c-05aa-4b17-be28-d65a031ed75a', metadata={'source': 'appendix-keywords.txt'}, page_content='Semantic Search\\n\\nDefinition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.\\nRelated keywords: embedding, database, vectorization, vectorization\\n\\nEmbedding\\n\\nDefinition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to understand and process the text.\\nExample: Represent the word “apple” as a vector such as [0.65, -0.23, 0.17].\\nRelated keywords: natural language processing, vectorization, deep learning\\n\\nToken\\n\\nDefinition: A token is a breakup of text into smaller units. These can typically be words, sentences, or phrases.\\nExample: Split the sentence “I am going to school” into “I am”, “to school”, and “going”.\\nAssociated keywords: tokenization, natural language processing, parsing\\n\\nTokenizer'),\n",
       " Document(id='4223cae7-00fc-44d1-a133-b2cdb5b42757', metadata={'source': 'appendix-keywords.txt'}, page_content='Definition: FAISS is a fast similarity search library developed by Facebook, specifically designed to efficiently search for similar vectors in large vector sets.\\nExample: FAISS can be used to quickly find similar images among millions of image vectors.\\nRelated keywords: vector search, machine learning, database optimization\\n\\nOpen Source\\n\\nDefinition: Open source refers to software whose source code is publicly available and can be freely used, modified, and distributed by anyone. This plays an important role in fostering collaboration and innovation.\\nExample: The Linux operating system is a prominent open source project.\\nRelated keywords: software development, community, technical collaboration\\n\\nStructured Data'),\n",
       " Document(id='d27bf8f4-883f-4694-8812-cf1dcf3d8e30', metadata={'source': 'appendix-keywords.txt'}, page_content=\"Word2Vec\\n\\nDefinition: Word2Vec is a natural language processing technique that maps words to a vector space to represent semantic relationships between words. It generates vectors based on the contextual similarity of words.\\nExample: In a Word2Vec model, “king” and “queen” are represented as vectors in close proximity to each other.\\nRelated keywords: natural language processing, embeddings, semantic similarity\\n\\nLLM (Large Language Model)\\n\\nDefinition: LLM refers to large-scale language models trained on large amounts of textual data. These models are used for a variety of natural language understanding and generation tasks.\\nExample: OpenAI's GPT series is a typical large-scale language model.\\nRelated keywords: natural language processing, deep learning, text generation\\n\\nFAISS (Facebook AI Similarity Search)\"),\n",
       " Document(id='a701e729-d87f-4714-810e-f640351bd498', metadata={'source': 'appendix-keywords.txt'}, page_content='CSV\\n\\nDefinition: CSV(Comma-Separated Values) is a file format for storing data, where each data value is separated by a comma. It is used for simple storage and exchange of tabular data.\\nExample: A CSV file with the headers Name, Age, and Occupation might contain data such as Hong Gil-dong, 30, Developer.\\nRelated keywords: data format, file processing, data exchange\\n\\nJSON\\n\\nDefinition: JSON(JavaScript Object Notation) is a lightweight data interchange format that represents data objects using text that is readable to both humans and machines.\\nExample: {“Name”: “HongGilDong”, ‘Age’: 30, “Occupation”: “Developer\"} is data in JSON format.\\nRelated keywords: data exchange, web development, APIs\\n\\nTransformer')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 5, \"score_threshold\": 0.5},\n",
    ")\n",
    "retriever.invoke(\"What is a vector store?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer the question based on the context provided. If the answer is not provided in the context, say 'I don't know'.\"\n",
    "    \"\\n\\nHere is the context: {context}\"\n",
    "    \"--------------------------------\"\n",
    "    \"\\n\\nHere is the question provided by the user: {question}\",\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "query = \"What is a Tokenizer?\"\n",
    "\n",
    "context = retriever.invoke(query)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Semantic Search\\n\\nDefinition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.\\nRelated keywords: embedding, database, vectorization, vectorization\\n\\nEmbedding\\n\\nDefinition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to understand and process the text.\\nExample: Represent the word “apple” as a vector such as [0.65, -0.23, 0.17].\\nRelated keywords: natural language processing, vectorization, deep learning\\n\\nToken\\n\\nDefinition: A token is a breakup of text into smaller units. These can typically be words, sentences, or phrases.\\nExample: Split the sentence “I am going to school” into “I am”, “to school”, and “going”.\\nAssociated keywords: tokenization, natural language processing, parsing\\n\\nTokenizer',\n",
       " 'Tokenizer\\n\\nDefinition: A tokenizer is a tool that splits text data into tokens. It is used to preprocess data in natural language processing.\\nExample: Split the sentence “I love programming.” into [“I”, “love”, “programming”, “.”].\\nAssociated keywords: tokenization, natural language processing, parsing\\n\\nVectorStore\\n\\nDefinition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.\\nRelated keywords: embedding, database, vectorization, vectorization\\n\\nSQL\\n\\nDefinition: SQL(Structured Query Language) is a programming language for managing data in a database. You can query, modify, insert, delete, and more data.\\nExample: SELECT * FROM users WHERE age > 18; looks up information about users who are 18 years old or older.\\nAssociated keywords: database, query, data management, data management\\n\\nCSV',\n",
       " 'Definition: Structured data is data that is organized according to a set format or schema. It can be easily searched and analyzed in databases, spreadsheets, etc.\\nExample: A table of customer information stored in a relational database is an example of structured data.\\nRelated keywords: database, data analysis, data modeling, data modeling\\n\\nParser\\n\\nDefinition: A parser is a tool that analyzes given data (strings, files, etc.) and converts it into a structured form. It is used for parsing programming languages or processing file data.\\nExample: Parsing an HTML document to generate the DOM structure of a web page is an example of parsing.\\nAssociated keywords: parsing, compiler, data processing\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)',\n",
       " \"Definition: Transformers are a type of deep learning model used in natural language processing, mainly for translation, summarization, text generation, etc. It is based on the Attention mechanism.\\nExample: Google Translator uses transformer models to perform translations between different languages.\\nRelated keywords: Deep learning, Natural language processing, Attention\\n\\nHuggingFace\\n\\nDefinition: HuggingFace is a library that provides a variety of pre-trained models and tools for natural language processing. It helps researchers and developers to easily perform NLP tasks.\\nExample: You can use HuggingFace's Transformers library to perform tasks such as sentiment analysis, text generation, and more.\\nRelated keywords: natural language processing, deep learning, libraries\\n\\nDigital Transformation\",\n",
       " 'Definition: TF-IDF is a statistical measure used to evaluate the importance of a word within a document. It takes into account the frequency of the word within the document and the sparsity of the word in the entire document set.\\nExample: A word that occurs infrequently in many documents has a high TF-IDF value.\\nRelated keywords: natural language processing, information retrieval, data mining\\n\\nDeep Learning\\n\\nDefinition: Deep learning is a branch of machine learning that uses artificial neural networks to solve complex problems. It focuses on learning high-level representations from data.\\nExamples: Deep learning models are used in image recognition, speech recognition, natural language processing, and more.\\nRelated keywords: Artificial neural networks, machine learning, data analytics\\n\\nSchema']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [text_info.page_content for text_info in context]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "formatted_prompt = prompt.format(context=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A tokenizer is a tool that splits text data into tokens. It is used to preprocess data in natural language processing. For example, it can split the sentence “I love programming.” into [“I”, “love”, “programming”, “.”].', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 953, 'total_tokens': 1005, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-227a8949-8d8a-405f-b8e1-f4910bff9e1c-0', usage_metadata={'input_tokens': 953, 'output_tokens': 52, 'total_tokens': 1005, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_prompt\n",
    "\n",
    "llm_response = llm.invoke(formatted_prompt)\n",
    "\n",
    "llm_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tokenizer is a tool that splits text data into tokens. It is used to preprocess data in natural\n",
      "language processing. For example, it can split the sentence “I love programming.” into [“I”, “love”,\n",
      "“programming”, “.”].\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "print(textwrap.fill(llm_response.content, width=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetrievalQA\n",
    "Link -https://python.langchain.com/docs/versions/migrating_chains/retrieval_qa/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hrithikkoduri/Desktop/Course/venv/lib/python3.13/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# See full prompt at https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/my/qn7jj99x5vl2bm8stjp1zbh00000gn/T/ipykernel_80369/3412691558.py:7: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  qa_chain(\"What is a tokenizer?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is a tokenizer?',\n",
       " 'result': 'A tokenizer is a tool that splits text data into smaller units called tokens, which are essential for preprocessing in natural language processing. For example, it can break the sentence “I love programming.” into the tokens [“I”, “love”, “programming”, “.”]. Tokenization helps in analyzing and understanding text data more effectively.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_llm(\n",
    "    llm, \n",
    "    retriever=vector_store.as_retriever(), \n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "qa_chain(\"What is a tokenizer?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversation QA Chain - https://python.langchain.com/v0.1/docs/use_cases/chatbots/retrieval/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
