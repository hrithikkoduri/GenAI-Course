{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting Data from different sources and stroing dpcuments\n",
    "- Splitting those text data, chunking\n",
    "- Emdedding/Index\n",
    "- Storing it in vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document\n",
    "Class for storing a piece of text and its associated metadata.\n",
    "\n",
    "- page_content (Required): Stores a piece of text as a string.\n",
    "- metadata (Optional): Stores metadata related to page_content as a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install langchain langchain_core langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'metadata': {'source': 'example.com'},\n",
       " 'page_content': 'Hello, world!',\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document = Document(page_content=\"Hello, world!\", metadata={\"source\": \"example.com\"})\n",
    "\n",
    "document.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'metadata': {'source': 'example.com', 'page_no': 1},\n",
       " 'page_content': 'Hello, world!',\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "document.metadata[\"page_no\"] = 1\n",
    "\n",
    "document.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loader\n",
    "Document Loader is a class that loads Documents from various sources.\n",
    "\n",
    "Listed below are some examples of Document Loaders.\n",
    "\n",
    "- PyPDFLoader: Loads PDF files\n",
    "- WebBasedLoader: Load HTML files\n",
    "- CSVLoader: Loads CSV files\n",
    "- JSONLoader: Loads JSON files\n",
    "- TextLoader: Loads text files\n",
    "- DirectoryLoader: Loads documents from a directory\n",
    "\n",
    "Check out the link for more document loaders and their respective libraries - https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"data/01-document-loader-sample.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Document Content:  October 2016 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "THE NATIONAL  \n",
      "ARTIFICIAL INTELLIGENCE \n",
      "RESEARCH AND DEVELOPMENT \n",
      "ST\n",
      "Document Metadata:  {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2016-10-11T15:32:07-04:00', 'author': 'NITRD AI Task Force', 'keywords': 'Artificial Intelligence, AI, Machine Learning, ML, Deep Learning, DL, Neural Networks,', 'moddate': '2016-10-11T20:19:58-04:00', 'title': 'The National Artificial Intelligence Research and Development Strategic Plan', 'source': 'data/01-document-loader-sample.pdf', 'total_pages': 48, 'page': 0, 'page_label': '1'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "Document Content:  ii\n",
      "Document Metadata:  {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2016-10-11T15:32:07-04:00', 'author': 'NITRD AI Task Force', 'keywords': 'Artificial Intelligence, AI, Machine Learning, ML, Deep Learning, DL, Neural Networks,', 'moddate': '2016-10-11T20:19:58-04:00', 'title': 'The National Artificial Intelligence Research and Development Strategic Plan', 'source': 'data/01-document-loader-sample.pdf', 'total_pages': 48, 'page': 1, 'page_label': '2'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "Document Content:  iii \n",
      "About the National Science and Technology Council \n",
      "The National Science and Technology Council \n",
      "Document Metadata:  {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2016-10-11T15:32:07-04:00', 'author': 'NITRD AI Task Force', 'keywords': 'Artificial Intelligence, AI, Machine Learning, ML, Deep Learning, DL, Neural Networks,', 'moddate': '2016-10-11T20:19:58-04:00', 'title': 'The National Artificial Intelligence Research and Development Strategic Plan', 'source': 'data/01-document-loader-sample.pdf', 'total_pages': 48, 'page': 2, 'page_label': '3'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "Document Content:  iv \n",
      "Copyright Information \n",
      "This is a work of the U.S. Government and is in the public domain. It may\n",
      "Document Metadata:  {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2016-10-11T15:32:07-04:00', 'author': 'NITRD AI Task Force', 'keywords': 'Artificial Intelligence, AI, Machine Learning, ML, Deep Learning, DL, Neural Networks,', 'moddate': '2016-10-11T20:19:58-04:00', 'title': 'The National Artificial Intelligence Research and Development Strategic Plan', 'source': 'data/01-document-loader-sample.pdf', 'total_pages': 48, 'page': 3, 'page_label': '4'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "Document Content:  \n",
      "Document Metadata:  {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2016-10-11T15:32:07-04:00', 'author': 'NITRD AI Task Force', 'keywords': 'Artificial Intelligence, AI, Machine Learning, ML, Deep Learning, DL, Neural Networks,', 'moddate': '2016-10-11T20:19:58-04:00', 'title': 'The National Artificial Intelligence Research and Development Strategic Plan', 'source': 'data/01-document-loader-sample.pdf', 'total_pages': 48, 'page': 4, 'page_label': '5'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "Document Content:  vi\n",
      "Document Metadata:  {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2016-10-11T15:32:07-04:00', 'author': 'NITRD AI Task Force', 'keywords': 'Artificial Intelligence, AI, Machine Learning, ML, Deep Learning, DL, Neural Networks,', 'moddate': '2016-10-11T20:19:58-04:00', 'title': 'The National Artificial Intelligence Research and Development Strategic Plan', 'source': 'data/01-document-loader-sample.pdf', 'total_pages': 48, 'page': 5, 'page_label': '6'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 7:\n",
      "Document Content:  vii \n",
      "National Science and Technology Council \n",
      "Chair \n",
      "John P. Holdren \n",
      "Assistant to the President for\n",
      "Document Metadata:  {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2016-10-11T15:32:07-04:00', 'author': 'NITRD AI Task Force', 'keywords': 'Artificial Intelligence, AI, Machine Learning, ML, Deep Learning, DL, Neural Networks,', 'moddate': '2016-10-11T20:19:58-04:00', 'title': 'The National Artificial Intelligence Research and Development Strategic Plan', 'source': 'data/01-document-loader-sample.pdf', 'total_pages': 48, 'page': 6, 'page_label': '7'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 8:\n",
      "Document Content:  viii \n",
      " \n",
      "John Launchbury \n",
      "Defense Advanced Research Projects Agency \n",
      "Faisal D’Souza \n",
      "Technical Coordi\n",
      "Document Metadata:  {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2016-10-11T15:32:07-04:00', 'author': 'NITRD AI Task Force', 'keywords': 'Artificial Intelligence, AI, Machine Learning, ML, Deep Learning, DL, Neural Networks,', 'moddate': '2016-10-11T20:19:58-04:00', 'title': 'The National Artificial Intelligence Research and Development Strategic Plan', 'source': 'data/01-document-loader-sample.pdf', 'total_pages': 48, 'page': 7, 'page_label': '8'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 9:\n",
      "Document Content:  NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN \n",
      " \n",
      " 1 \n",
      "Contents \n",
      "About the \n",
      "Document Metadata:  {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2016-10-11T15:32:07-04:00', 'author': 'NITRD AI Task Force', 'keywords': 'Artificial Intelligence, AI, Machine Learning, ML, Deep Learning, DL, Neural Networks,', 'moddate': '2016-10-11T20:19:58-04:00', 'title': 'The National Artificial Intelligence Research and Development Strategic Plan', 'source': 'data/01-document-loader-sample.pdf', 'total_pages': 48, 'page': 8, 'page_label': '9'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 10:\n",
      "Document Content:  NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN \n",
      " \n",
      " 2\n",
      "Document Metadata:  {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2016-10-11T15:32:07-04:00', 'author': 'NITRD AI Task Force', 'keywords': 'Artificial Intelligence, AI, Machine Learning, ML, Deep Learning, DL, Neural Networks,', 'moddate': '2016-10-11T20:19:58-04:00', 'title': 'The National Artificial Intelligence Research and Development Strategic Plan', 'source': 'data/01-document-loader-sample.pdf', 'total_pages': 48, 'page': 9, 'page_label': '10'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(docs[0:10]):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(\"Document Content: \", doc.page_content[0:100])\n",
    "    print(\"Document Metadata: \", doc.metadata)\n",
    "    print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aload()\n",
    "Asynchronously loads Documents and returns them as a list[Document].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = await loader.aload()\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPDFDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# directory path\n",
    "loader = PyPDFDirectoryLoader(\"./data/\")\n",
    "\n",
    "# load documents\n",
    "docs = loader.load()\n",
    "\n",
    "# print the number of documents\n",
    "docs_len = len(docs)\n",
    "print(docs_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebBased Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Load news article content using WebBaseLoader\n",
    "loader = WebBaseLoader(\n",
    "   web_paths=(\"https://techcrunch.com/2024/12/28/google-ceo-says-ai-model-gemini-will-the-companys-biggest-focus-in-2025/\",),\n",
    "   # Configure BeautifulSoup to parse only specific div elements\n",
    "   bs_kwargs=dict(\n",
    "       parse_only=bs4.SoupStrainer(\n",
    "           \"div\",\n",
    "       )\n",
    "   ),\n",
    "   # Set user agent in request header to mimic browser\n",
    "   header_template={\n",
    "       \"User_Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\",\n",
    "   },\n",
    ")\n",
    "\n",
    "# Load and process the documents\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n TechCrunch Desktop Logo\\n\\n\\n\\n\\n TechCrunch Mobile Logo\\n\\n\\n\\n\\nLatestStartupsVentureAppleSecurityAIAppsStartup Battlefield\\n\\nEventsPodcastsNewsletters\\n\\n\\n\\n\\n\\n\\n\\n\\t\\tSign In\\t\\n\\n\\n\\n\\n\\n\\n\\nSearchSubmit\\n\\n\\n\\n\\n\\n\\n\\nSite Search Toggle\\n\\n\\n\\n\\nMega Menu Toggle\\n\\n\\n\\n\\n\\nTopics\\n\\n\\n\\n\\t\\tLatest\\t\\n\\n\\n\\n\\t\\tAI\\t\\n\\n\\n\\n\\t\\tAmazon\\t\\n\\n\\n\\n\\t\\tApps\\t\\n\\n\\n\\n\\t\\tBiotech & Health\\t\\n\\n\\n\\n\\t\\tClimate\\t\\n\\n\\n\\n\\t\\tCloud Computing\\t\\n\\n\\n\\n\\t\\tCommerce\\t\\n\\n\\n\\n\\t\\tCrypto\\t\\n\\n\\n\\n\\t\\tEnterprise\\t\\n\\n\\n\\n\\t\\tEVs\\t\\n\\n\\n\\n\\t\\tFintech\\t\\n\\n\\n\\n\\t\\tFundraising\\t\\n\\n\\n\\n\\t\\tGadgets\\t\\n\\n\\n\\n\\t\\tGaming\\t\\n\\n\\n\\n\\t\\tGoogle\\t\\n\\n\\n\\n\\t\\tGovernment & Policy\\t\\n\\n\\n\\n\\n\\t\\tHardware\\t\\n\\n\\n\\n\\t\\tInstagram\\t\\n\\n\\n\\n\\t\\tLayoffs\\t\\n\\n\\n\\n\\t\\tMedia & Entertainment\\t\\n\\n\\n\\n\\t\\tMeta\\t\\n\\n\\n\\n\\t\\tMicrosoft\\t\\n\\n\\n\\n\\t\\tPrivacy\\t\\n\\n\\n\\n\\t\\tRobotics\\t\\n\\n\\n\\n\\t\\tSecurity\\t\\n\\n\\n\\n\\t\\tSocial\\t\\n\\n\\n\\n\\t\\tSpace\\t\\n\\n\\n\\n\\t\\tStartups\\t\\n\\n\\n\\n\\t\\tTikTok\\t\\n\\n\\n\\n\\t\\tTransportation\\t\\n\\n\\n\\n\\t\\tVenture\\t\\n\\n\\n\\n\\n\\n\\n\\nMore from TechCrunch\\n\\t\\t\\n\\n\\n\\t\\tEvents\\t\\n\\n\\n\\n\\t\\tStartup Battlefield\\t\\n\\n\\n\\n\\t\\tStrictlyVC\\t\\n\\n\\n\\n\\t\\tNewsletters\\t\\n\\n\\n\\n\\t\\tPodcasts\\t\\n\\n\\n\\n\\t\\tVideos\\t\\n\\n\\n\\n\\t\\tPartner Content\\t\\n\\n\\n\\n\\t\\tTechCrunch Brand Studio\\t\\n\\n\\n\\n\\t\\tCrunchboard\\t\\n\\n\\n\\n\\t\\tContact Us\\t\\n\\n\\n\\n\\n\\n\\t\\tSign In\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n\\n\\n\\n\\nIn Brief\\n\\nPosted:\\n2:00 PM PST · December 28, 2024\\n\\n\\nImage Credits:Justin Sullivan / Getty Images\\n\\n\\n\\n\\n\\n\\n\\n\\nAnthony Ha\\n\\n\\n\\nGoogle CEO says AI model Gemini will be the company’s ‘biggest focus’ in 2025\\n\\nGoogle CEO Sundar Pichai reportedly told Google employees that 2025 will be a “critical” year for the company.\\nCNBC reports that it obtained audio from a December 18 strategy meeting where Pichai and other executives put on ugly holiday sweaters and laid out their priorities for the coming year.\\n\\n\\n\\n\\n\\n\\n\\n\\n“I think 2025 will be critical,” Pichai said. “I think it’s really important we internalize the urgency of this moment, and need to move faster as a company. The stakes are high.”\\nThe moment, of course, is one where tech companies like Google are making heavy investments in AI, and often with mixed results. Pichai acknowledged that the company has some catching up to do on the AI side — he described the Gemini app (based on the company’s AI model of the same name) as having “strong momentum,” while also acknowledging “we have some work to do in 2025 to close the gap and establish a leadership position there as well.”\\n“Scaling Gemini on the consumer side will be our biggest focus next year,” he said.\\n\\nTechCrunch has an AI-focused newsletter! Sign up here to get it in your inbox every Wednesday.\\n\\n\\n\\nTopics\\n\\nAI, Google, In Brief, Sundar Pichai \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNewsletters\\n\\nSee More\\n\\n\\nSubscribe for the industry’s biggest tech news\\n\\n\\n\\n\\n\\n\\nTechCrunch Daily News\\nEvery weekday and Sunday, you can get the best of TechCrunch’s coverage.\\n\\n\\n\\n\\n\\nTechCrunch AI\\nTechCrunch's AI experts cover the latest news in the fast-moving field.\\n\\n\\n\\n\\n\\nTechCrunch Space\\nEvery Monday, gets you up to speed on the latest advances in aerospace.\\n\\n\\n\\n\\n\\nStartups Weekly\\nStartups are the core of TechCrunch, so get our best coverage delivered weekly.\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\tNo newsletters selected.\\n\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\nSubscribe\\n\\nBy submitting your email, you agree to our Terms and Privacy Notice.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated\\n\\n\\nLatest in AI\\n\\nSee More\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\nIn Brief\\n\\n\\n\\n \\nRussian propoganda is reportely influencing AI chatbot results\\n\\n\\n\\nKyle Wiggers\\n\\n\\n\\t34 minutes ago\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\nTC Sessions: AI\\n\\n\\nLast day to apply to be a TechCrunch Sessions: AI speaker\\n\\n\\n\\nTechCrunch Events\\n\\n\\n\\t1 hour ago\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\nIn Brief\\n\\n\\n\\n \\nMeta’s next Llama models may have upgraded voice features\\n\\n\\n\\nKyle Wiggers\\n\\n\\n\\t2 hours ago\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nX\\nLinkedIn\\nFacebook\\nInstagram\\nyouTube\\nMastodon\\nThreads\\nBluesky\\n\\n\\n\\n\\nTechCrunchStaffContact UsAdvertiseCrunchboard JobsSite Map\\nTerms of ServicePrivacy PolicyRSS Terms of UsePrivacy Placeholder 1Privacy Placeholder 2Privacy Placeholder 3Privacy Placeholder 4Code of ConductAbout Our Ads\\nGPT-4.5Goodbye, SkypeYC Controversy2025 Data BreachesMeme CoinsTech LayoffsChatGPT\\n\\n\\n\\n© 2024 Yahoo.\\n\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='PassengerId: 1\n",
      "Survived: 0\n",
      "Pclass: 3\n",
      "Name: Braund, Mr. Owen Harris\n",
      "Sex: male\n",
      "Age: 22\n",
      "SibSp: 1\n",
      "Parch: 0\n",
      "Ticket: A/5 21171\n",
      "Fare: 7.25\n",
      "Cabin: \n",
      "Embarked: S' metadata={'source': './data/titanic.csv', 'row': 0}\n",
      "page_content='PassengerId: 2\n",
      "Survived: 1\n",
      "Pclass: 1\n",
      "Name: Cumings, Mrs. John Bradley (Florence Briggs Thayer)\n",
      "Sex: female\n",
      "Age: 38\n",
      "SibSp: 1\n",
      "Parch: 0\n",
      "Ticket: PC 17599\n",
      "Fare: 71.2833\n",
      "Cabin: C85\n",
      "Embarked: C' metadata={'source': './data/titanic.csv', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# Create CSVLoader instance\n",
    "loader = CSVLoader(file_path=\"./data/titanic.csv\")\n",
    "\n",
    "# Load documents\n",
    "docs = loader.load()\n",
    "\n",
    "for record in docs[:2]:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId: 2\n",
      "Survived: 1\n",
      "Pclass: 1\n",
      "Name: Cumings, Mrs. John Bradley (Florence Briggs Thayer)\n",
      "Sex: female\n",
      "Age: 38\n",
      "SibSp: 1\n",
      "Parch: 0\n",
      "Ticket: PC 17599\n",
      "Fare: 71.2833\n",
      "Cabin: C85\n",
      "Embarked: C\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passenger ID: 1\n",
      "Survival (1: Survived, 0: Died): 0\n",
      "Passenger Class: 3\n",
      "Name: Braund, Mr. Owen Harris\n",
      "Sex: male\n",
      "Age: 22\n",
      "Number of Siblings/Spouses Aboard: 1\n",
      "Number of Parents/Children Aboard: 0\n",
      "Ticket Number: A/5 21171\n",
      "Fare: 7.25\n",
      "Cabin: \n",
      "Port of Embarkation: S\n"
     ]
    }
   ],
   "source": [
    "loader = CSVLoader(\n",
    "    file_path=\"./data/titanic.csv\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",\n",
    "        \"quotechar\": '\"',\n",
    "        \"fieldnames\": [\n",
    "            \"Passenger ID\",\n",
    "            \"Survival (1: Survived, 0: Died)\",\n",
    "            \"Passenger Class\",\n",
    "            \"Name\",\n",
    "            \"Sex\",\n",
    "            \"Age\",\n",
    "            \"Number of Siblings/Spouses Aboard\",\n",
    "            \"Number of Parents/Children Aboard\",\n",
    "            \"Ticket Number\",\n",
    "            \"Fare\",\n",
    "            \"Cabin\",\n",
    "            \"Port of Embarkation\",\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other loaders - \n",
    "- ExcelLoader\n",
    "- JSONLoader\n",
    "- UnstructuredHTMLLoader\n",
    "- TXTLoader\n",
    ", etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
