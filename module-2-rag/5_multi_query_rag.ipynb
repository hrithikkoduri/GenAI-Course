{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load all environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "## LLM\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "## Pinecone Vector Database\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hrithikkoduri/Desktop/Course/venv/lib/python3.13/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"rag-multi-query-index\" # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load blog\n",
    "import bs4\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from pprint import pprint\n",
    "\n",
    "#### INDEXING ####\n",
    "\n",
    "# Load Document (Uploading one file at a time)\n",
    "pdf_file_path = \"./data/langchain_turing.pdf\"\n",
    "loader = PyPDFLoader(pdf_file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# Upload muiltiple PDF files from a directory\n",
    "# pdf_file_paths = <enter your path here>\n",
    "# loader = PyPDFDirectoryLoader(pdf_file_paths)\n",
    "\n",
    "# docs_dir = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=2000, \n",
    "    chunk_overlap=500)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index\n",
    "vectorstore = Pinecone.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), \n",
    "    index_name=index_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 5, \"score_threshold\": 0.5},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Query RAG\n",
    "\n",
    "Python doc- https://python.langchain.com/docs/how_to/MultiQueryRetriever/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multi Query RAG](./images/multi_query_rag.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How does LangChain leverage modular components like LangGraph, LangSmith, and LangServe to address challenges in building scalable and secure LLM-powered applications?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Question(BaseModel):\n",
    "    generated_questions: list[str]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the roles of LangGraph, LangSmith, and LangServe in LangChain for developing scalable and secure applications with LLMs?', 'In what ways does LangChain utilize modular components such as LangGraph, LangSmith, and LangServe to enhance the scalability and security of LLM applications?', 'Can you explain how LangChain incorporates LangGraph, LangSmith, and LangServe to tackle issues related to scalability and security in LLM-powered applications?', 'How do the modular components of LangChain, including LangGraph, LangSmith, and LangServe, contribute to building secure and scalable applications using LLM technology?', 'What challenges in LLM application development does LangChain address through its use of components like LangGraph, LangSmith, and LangServe?']\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "generated_questions_prompt = prompt_perspectives.invoke(\n",
    "    {\"question\": question}\n",
    ")\n",
    "llm_with_structured_output = llm.with_structured_output(Question)\n",
    "\n",
    "\n",
    "generated_questions = llm_with_structured_output.invoke(generated_questions_prompt)\n",
    "\n",
    "print(generated_questions.generated_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the roles of LangGraph, LangSmith, and LangServe in LangChain for developing scalable and secure applications with LLMs?\n",
      "In what ways does LangChain utilize modular components such as LangGraph, LangSmith, and LangServe to enhance the scalability and security of LLM applications?\n",
      "Can you explain how LangChain incorporates LangGraph, LangSmith, and LangServe to tackle issues related to scalability and security in LLM-powered applications?\n",
      "How do the modular components of LangChain, including LangGraph, LangSmith, and LangServe, contribute to building secure and scalable applications using LLM technology?\n",
      "What challenges in LLM application development does LangChain address through its use of components like LangGraph, LangSmith, and LangServe?\n"
     ]
    }
   ],
   "source": [
    "for que in generated_questions.generated_questions:\n",
    "    print(que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def generate_questions(question):   \n",
    "\n",
    "    # Multi Query: Different Perspectives\n",
    "    template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "    prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "    generated_questions_prompt = prompt_perspectives.invoke(\n",
    "        {\"question\": question}\n",
    "    )\n",
    "    llm_with_structured_output = llm.with_structured_output(Question)\n",
    "\n",
    "\n",
    "    generated_questions = llm_with_structured_output.invoke(generated_questions_prompt)\n",
    "\n",
    "    return generated_questions.generated_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs_retriever = generate_questions | retriever.map()\n",
    "\n",
    "question = \"How does LangChain leverage modular components like LangGraph, LangSmith, and LangServe to address challenges in building scalable and secure LLM-powered applications?\"\n",
    "\n",
    "all_docs = all_docs_retriever.invoke(question)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Results from 1th query:***********\n",
      "10 Vasilios Mavroudis\n",
      "3.4 Integration with LangChain and LangSmith\n",
      "LangGraph integrates seamlessly w\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2 Vasilios Mavroudis\n",
      "stateful, and contextually aware applications with ease. Its suite of compo-\n",
      "ne\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LangChain\n",
      "Vasilios Mavroudis\n",
      "Alan Turing Institute\n",
      "vmavroudis@turing.ac.uk\n",
      "Abstract. LangChain is a \n",
      "----------------------------------------------------------------------------------------------------\n",
      "6 Vasilios Mavroudis\n",
      "1.5 Advanced Components\n",
      "Beyond these core elements, LangChain offers advanced m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LangChain 3\n",
      "needs, providing a flexible foundation for building scalable, secure, and multi-\n",
      "functio\n",
      "----------------------------------------------------------------------------------------------------\n",
      "***********Results from 2th query:***********\n",
      "2 Vasilios Mavroudis\n",
      "stateful, and contextually aware applications with ease. Its suite of compo-\n",
      "ne\n",
      "----------------------------------------------------------------------------------------------------\n",
      "10 Vasilios Mavroudis\n",
      "3.4 Integration with LangChain and LangSmith\n",
      "LangGraph integrates seamlessly w\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LangChain 5\n",
      "and relevance. RAG allows models to access up-to-date information, extending\n",
      "their capab\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LangChain 13\n",
      "LangChain’s security model addresses many of these concerns, yet challenges\n",
      "persist, pa\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LangChain\n",
      "Vasilios Mavroudis\n",
      "Alan Turing Institute\n",
      "vmavroudis@turing.ac.uk\n",
      "Abstract. LangChain is a \n",
      "----------------------------------------------------------------------------------------------------\n",
      "***********Results from 3th query:***********\n",
      "2 Vasilios Mavroudis\n",
      "stateful, and contextually aware applications with ease. Its suite of compo-\n",
      "ne\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LangChain 3\n",
      "needs, providing a flexible foundation for building scalable, secure, and multi-\n",
      "functio\n",
      "----------------------------------------------------------------------------------------------------\n",
      "10 Vasilios Mavroudis\n",
      "3.4 Integration with LangChain and LangSmith\n",
      "LangGraph integrates seamlessly w\n",
      "----------------------------------------------------------------------------------------------------\n",
      "6 Vasilios Mavroudis\n",
      "1.5 Advanced Components\n",
      "Beyond these core elements, LangChain offers advanced m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LangChain 5\n",
      "and relevance. RAG allows models to access up-to-date information, extending\n",
      "their capab\n",
      "----------------------------------------------------------------------------------------------------\n",
      "***********Results from 4th query:***********\n",
      "10 Vasilios Mavroudis\n",
      "3.4 Integration with LangChain and LangSmith\n",
      "LangGraph integrates seamlessly w\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2 Vasilios Mavroudis\n",
      "stateful, and contextually aware applications with ease. Its suite of compo-\n",
      "ne\n",
      "----------------------------------------------------------------------------------------------------\n",
      "6 Vasilios Mavroudis\n",
      "1.5 Advanced Components\n",
      "Beyond these core elements, LangChain offers advanced m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LangChain\n",
      "Vasilios Mavroudis\n",
      "Alan Turing Institute\n",
      "vmavroudis@turing.ac.uk\n",
      "Abstract. LangChain is a \n",
      "----------------------------------------------------------------------------------------------------\n",
      "LangChain 3\n",
      "needs, providing a flexible foundation for building scalable, secure, and multi-\n",
      "functio\n",
      "----------------------------------------------------------------------------------------------------\n",
      "***********Results from 5th query:***********\n",
      "2 Vasilios Mavroudis\n",
      "stateful, and contextually aware applications with ease. Its suite of compo-\n",
      "ne\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LangChain\n",
      "Vasilios Mavroudis\n",
      "Alan Turing Institute\n",
      "vmavroudis@turing.ac.uk\n",
      "Abstract. LangChain is a \n",
      "----------------------------------------------------------------------------------------------------\n",
      "10 Vasilios Mavroudis\n",
      "3.4 Integration with LangChain and LangSmith\n",
      "LangGraph integrates seamlessly w\n",
      "----------------------------------------------------------------------------------------------------\n",
      "6 Vasilios Mavroudis\n",
      "1.5 Advanced Components\n",
      "Beyond these core elements, LangChain offers advanced m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LangChain 3\n",
      "needs, providing a flexible foundation for building scalable, secure, and multi-\n",
      "functio\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,  docs in enumerate(all_docs):\n",
    "    print(f\"***********Results from {i+1}th query:***********\")\n",
    "    for doc in docs:\n",
    "        print(doc.page_content[:100])\n",
    "        print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_docs(all_docs):\n",
    "    unique_docs = []\n",
    "    for docs in all_docs:\n",
    "        for doc in docs:\n",
    "            if doc not in unique_docs:\n",
    "                unique_docs.append(doc)\n",
    "    return unique_docs\n",
    "\n",
    "unique_docs = get_unique_docs(all_docs)\n",
    "\n",
    "len(unique_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_retrieval_chain = generate_questions | retriever.map() | get_unique_docs\n",
    "\n",
    "question = \"How does LangChain leverage modular components like LangGraph, LangSmith, and LangServe to address challenges in building scalable and secure LLM-powered applications?\"\n",
    "\n",
    "context = final_retrieval_chain.invoke(question)\n",
    "\n",
    "len(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def generate_response(question):\n",
    "    rag_system_prompt = \"\"\"\n",
    "        You are an AI language model assistant. Your task is to answer the user question based on the provided context.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "    \"\"\"\n",
    "\n",
    "    rag_user_prompt = \"\"\"\n",
    "        Question: {question}\n",
    "    \"\"\"\n",
    "    context = final_retrieval_chain.invoke(question)\n",
    "\n",
    "    rag_system_message = SystemMessage(content=rag_system_prompt.format(context=context))\n",
    "    rag_user_message = HumanMessage(content=rag_user_prompt.format(question=question))\n",
    "\n",
    "    rag_prompt = [rag_system_message , rag_user_message]\n",
    "\n",
    "    response = llm.invoke(rag_prompt)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How does LangChain leverage modular components like LangGraph, LangSmith, and LangServe to address challenges in building scalable and secure LLM-powered applications?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_response(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "LangChain leverages its modular components—LangGraph, LangSmith, and LangServe—to effectively address the challenges of building scalable and secure applications powered by large language models (LLMs) in several ways:\n",
       "\n",
       "1. **LangGraph for Stateful Process Modeling**: \n",
       "   - LangGraph allows developers to structure applications using nodes and edges, facilitating complex branching and multi-agent workflows. This modular approach enables the creation of stateful and contextually aware applications, which can manage intricate processes and interactions efficiently. By modeling workflows as graphs, developers can visualize and optimize the flow of data and control, enhancing scalability.\n",
       "\n",
       "2. **LangSmith for Monitoring and Evaluation**: \n",
       "   - LangSmith provides essential tools for real-time performance monitoring, error tracking, and version control. It addresses key challenges in observability and optimization by allowing developers to trace interactions with LLMs and external data sources. This capability is crucial for identifying bottlenecks and ensuring that applications maintain high performance and reliability over time. LangSmith's evaluation tools also enable developers to test applications under real-world conditions, ensuring they meet performance standards.\n",
       "\n",
       "3. **LangServe for Scalable API Deployment**: \n",
       "   - LangServe simplifies the process of deploying LangChain applications as scalable REST APIs. It supports load balancing and can handle multiple API requests simultaneously, which is essential for applications experiencing high traffic. LangServe also includes features for auto-scaling, allowing the number of instances to adjust dynamically based on demand. This ensures consistent performance and responsiveness, making it suitable for production environments.\n",
       "\n",
       "Together, these components create a comprehensive toolkit that not only simplifies the development lifecycle of LLM applications but also enhances their scalability and security. By modularizing functionalities, LangChain allows developers to customize and extend their applications while addressing the complexities associated with integrating LLMs, managing state, and ensuring secure interactions with external systems. This modular architecture ultimately empowers developers to build innovative, efficient, and secure LLM-powered applications across various domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
