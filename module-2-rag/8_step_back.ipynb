{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load all environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "## LLM\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "## Pinecone Vector Database\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hrithikkoduri/Desktop/Course/venv/lib/python3.13/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"rag-setp-back-index\" # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load blog\n",
    "import bs4\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from pprint import pprint\n",
    "\n",
    "#### INDEXING ####\n",
    "\n",
    "# Load Document (Uploading one file at a time)\n",
    "pdf_file_path = \"./data/langchain_turing.pdf\"\n",
    "loader = PyPDFLoader(pdf_file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# Upload muiltiple PDF files from a directory\n",
    "# pdf_file_paths = <enter your path here>\n",
    "# loader = PyPDFDirectoryLoader(pdf_file_paths)\n",
    "\n",
    "# docs_dir = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=2000, \n",
    "    chunk_overlap=500)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index\n",
    "vectorstore = Pinecone.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), \n",
    "    index_name=index_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 5, \"score_threshold\": 0.5},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Step_Back](./images/rag_step_back.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link -https://arxiv.org/pdf/2310.06117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class StepBackQuestion(BaseModel):\n",
    "    question: str= Field(description=\"The question derived by stepping back and reprahsing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def step_back_function(question):\n",
    "    examples = [\n",
    "        {\n",
    "            \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "            \"output\": \"what can the members of The Police do?\",\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Jan Sindel’s was born in what country?\",\n",
    "            \"output\": \"what is Jan Sindel’s personal history?\",\n",
    "        },\n",
    "    ]\n",
    "    # We now transform these to example messages\n",
    "    example_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"ai\", \"{output}\"),\n",
    "        ]\n",
    "    )\n",
    "    few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        example_prompt=example_prompt,\n",
    "        examples=examples,\n",
    "    )\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\",\n",
    "            ),\n",
    "            # Few shot examples\n",
    "            few_shot_prompt,\n",
    "            # New question\n",
    "            (\"user\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model = \"gpt-4o-mini\", temperature=1)\n",
    "\n",
    "    step_back_question = llm.with_structured_output(StepBackQuestion).invoke(prompt.format(question = question))\n",
    "\n",
    "    return step_back_question.question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how does LangChain manage security in its integrations?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How does LangChain ensure security when integrating external services like vector databases and API providers in LLM applications?\"\n",
    "step_back_question = step_back_function(question)\n",
    "step_back_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_response(question):\n",
    "\n",
    "    # Response prompt \n",
    "    response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "    # {normal_context}\n",
    "    # {step_back_context}\n",
    "\n",
    "    # Original Question: {question}\n",
    "    # Answer:\"\"\"\n",
    "\n",
    "    step_back_question = step_back_question = step_back_function(question)\n",
    "\n",
    "    normal_context = retriever.invoke(question)\n",
    "    step_back_context = retriever.invoke(step_back_question)\n",
    "    \n",
    "    llm = ChatOpenAI(model = \"gpt-4o-mini\", temperature=1)\n",
    "\n",
    "    response = llm.invoke(response_prompt_template.format(question = question, normal_context = normal_context, step_back_context = step_back_context))\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How does LangChain ensure security when integrating external services like vector databases and API providers in LLM applications?\"\n",
    "\n",
    "answer = generate_response(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "LangChain incorporates several security measures to address the risks associated with integrating external services such as vector databases and API providers. Here are the key aspects of its security framework:\n",
       "\n",
       "1. **Granular Permissions**: LangChain enforces the principle of least privilege by allowing developers to set specific permissions. This minimizes the risk of unauthorized actions by limiting what external services can access or modify within the application. By configuring permissions carefully, developers can protect sensitive data and functionality.\n",
       "\n",
       "2. **Sandboxing**: LangChain employs sandboxing techniques to create isolated environments for executing code and accessing external services. This approach limits the exposure of sensitive information and reduces the risk of security vulnerabilities that could arise from integrating third-party services.\n",
       "\n",
       "3. **Defense in Depth**: The architecture includes multiple layers of security controls, ensuring that even if one layer is bypassed, others still provide protection. This layered security strategy strengthens the overall resilience of LLM applications against potential attacks.\n",
       "\n",
       "4. **Data Encryption**: For applications handling sensitive data, LangChain advocates for the implementation of robust encryption standards, such as end-to-end encryption. This practice helps ensure that data remains secure while being transmitted to and from external services, reducing the risk of data exposure.\n",
       "\n",
       "5. **Auditability and Monitoring**: LangChain features monitoring capabilities through components like LangSmith, which offers logging and tracking of application usage. This enables developers to detect anomalies and track interactions with external services. Real-time monitoring can help identify potential security breaches or misuse of the application.\n",
       "\n",
       "6. **Compliance Considerations**: Recognizing that certain sectors, such as finance and healthcare, have rigorous compliance requirements, LangChain addresses ongoing security challenges by promoting practices such as dynamic permission adjustments—where permission settings can adapt based on user interactions and roles. This is particularly crucial in contexts where compliance with data protection regulations is mandatory.\n",
       "\n",
       "7. **Proactive Security Analytics**: The integration of predictive analytics can also enhance security by identifying risks before they manifest as actual breaches. Utilizing machine learning models to analyze application logs allows developers to flag suspicious activities or vulnerabilities early in the process.\n",
       "\n",
       "In conclusion, while LangChain provides a comprehensive security model through these mechanisms, the inherent risks associated with relying on external providers necessitate continued vigilance and improvement in security practices to safeguard sensitive data within LLM applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
